---
sidebar_position: 2
---

# Course Overview

## 13-Week Curriculum Structure

This comprehensive course is designed as a quarter-long program covering the complete stack of Physical AI and Humanoid Robotics. The curriculum is divided into four main modules with introductory weeks to establish foundational knowledge.

### Weekly Breakdown

| Week | Topic | Module |
|------|-------|---------|
| 1 | Physical AI Foundations | Introduction |
| 2 | Sensor Systems | Introduction |
| 3 | ROS 2 Architecture, Nodes, Topics, Services | Module 1: The Robotic Nervous System |
| 4 | Python Integration with rclpy, URDF Basics | Module 1: The Robotic Nervous System |
| 5 | Detailed URDF for Humanoid Robots, Robot Control | Module 1: The Robotic Nervous System |
| 6 | Physics Simulation in Gazebo, Sensor Simulation | Module 2: The Digital Twin |
| 7 | Environment Building in Unity, Unity-ROS Integration | Module 2: The Digital Twin |
| 8 | NVIDIA Isaac Sim, Isaac ROS, VSLAM | Module 3: The AI-Robot Brain |
| 9 | Nav2 Framework, Path Planning, Bipedal Movement | Module 3: The AI-Robot Brain |
| 10 | AI Decision Making, Perception-Action Integration | Module 3: The AI-Robot Brain |
| 11 | Voice Commands with OpenAI Whisper | Module 4: Vision-Language-Action |
| 12 | LLM-based Cognitive Planning | Module 4: Vision-Language-Action |
| 13 | Capstone Project: Autonomous Humanoid | Module 4: Vision-Language-Action |

## Learning Objectives

### Module 1: The Robotic Nervous System (Weeks 3-5)
- Understand ROS 2 architecture and communication patterns
- Implement nodes, topics, services, and actions
- Integrate Python with rclpy for robotics applications
- Create and validate URDF models for humanoid robots

### Module 2: The Digital Twin (Weeks 6-7)
- Create physics-accurate simulations in Gazebo
- Build custom environments in Unity
- Simulate various sensors (LiDAR, Depth Cameras, IMUs)
- Integrate simulation environments with ROS 2

### Module 3: The AI-Robot Brain (Weeks 8-10)
- Implement NVIDIA Isaac tools for perception and navigation
- Develop VSLAM systems for localization and mapping
- Configure Nav2 for bipedal movement planning
- Integrate AI decision-making with robotic systems

### Module 4: Vision-Language-Action (Weeks 11-13)
- Process voice commands using OpenAI Whisper
- Implement LLM-based cognitive planning
- Integrate vision, language, and action systems
- Complete an autonomous humanoid capstone project

## Assessment Strategy

### Weekly Assessments
- Hands-on programming exercises
- Simulation and implementation challenges
- Code review and documentation tasks

### Module Projects
- Module-specific integrated projects
- Peer review and collaboration exercises
- Technical documentation and presentation

### Final Capstone
- Autonomous humanoid system integration
- Comprehensive project presentation
- Technical report and demonstration

## Prerequisites and Requirements

### Software Requirements
- ROS 2 Humble Hawksbill or later
- Gazebo simulation environment
- Unity (for digital twin components)
- NVIDIA Isaac Sim and Isaac ROS
- Python 3.8+ with relevant libraries
- Docusaurus for documentation

### Hardware Requirements
- Development: Modern laptop/desktop with 16GB+ RAM, dedicated GPU recommended
- Simulation: Compatible with standard gaming hardware
- Optional: Physical humanoid robot for advanced projects

## Getting Started

1. Complete the setup guide to install required software
2. Review the mathematical prerequisites
3. Familiarize yourself with basic robotics concepts
4. Begin with Week 1: Physical AI Foundations

The course is designed to progressively build your knowledge and skills, with each week building on the previous one. The modular structure allows for flexible pacing while maintaining the necessary sequence for foundational concepts.